# About
Summary of papers and projects for visual dialog, video dialog, and multimodal dialog

## Visual Dialog
### Year 2023
* ****`TCSVT 2023`**** Heterogeneous Knowledge Network for Visual Dialog [link](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9893870)


## Video Dialog/ AVSD/ Video-grounded Dialog Generation
### Year 2022
* ****`EMNLP 2022 Findings`**** Collaborative Reasoning on Multi-Modal Semantic Graphs for Video-Grounded Dialogue Generation [link](https://arxiv.org/pdf/2210.12460.pdf)
* ****`NAACL 2022`**** VGNMN: Video-grounded Neural Module Networks for Video-Grounded Dialogue Systems [link](https://aclanthology.org/2022.naacl-main.247.pdf)
* ****`EMNLP 2022`**** Information-Theoretic Text Hallucination Reduction for Video-grounded Dialogue [link](https://arxiv.org/pdf/2212.05765.pdf)
* ****`AAAI 2022 Workshop`**** Audio Visual Scene-Aware Dialog Generation with Transformer-based Video Representations [link](https://arxiv.org/pdf/2202.09979.pdf)
* ****`ICIP 2022`**** Video-Grounded Dialogues with Joint Video and Image Training [link](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9897613)
* ****`ECCV 2022`**** Video Dialog as Conversation about Objects Living in Space-Time [link](https://arxiv.org/pdf/2207.03656.pdf) [code](https://github.com/hoanganhpham1006/COST)

### Year 2021
* ****`TASLP 2021`**** End-to-End Recurrent Cross-Modality Attention for Video Dialogue [link](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9376964)
* ****`TASLP 2021`**** Bridging Text and Video: A Universal Multimodal Transformer for Audio-Visual Scene-Aware Dialog [link](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9376902)
* ****`AAAI 2021`**** Dynamic Graph Representation Learning for Video Dialog via Multi-Modal Shuffled Transformers [link](https://ojs.aaai.org/index.php/AAAI/article/view/16231)
* ****`AAAI 2021`**** Structured Co-reference Graph Attention for Video-grounded Dialogue [link](https://ojs.aaai.org/index.php/AAAI/article/view/16273)
* ****`ICLR 2021`**** Learning Reasoning Paths over Semantic Graphs for Video-grounded Dialogues [link](https://openreview.net/pdf?id=hPWj1qduVw8)

### Year 2020
* ****`TCSVT 2020`**** Video Dialog via Multi-Grained Convolutional Self-Attention Context Multi-Modal Networks [link](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8920126)
* ****`ACL 2020`**** Video-Grounded Dialogues with Pretrained Generation Language Models [link](https://aclanthology.org/2020.acl-main.518.pdf)
* ****`EMNLP 2020`**** BiST: Bi-directional Spatio-Temporal Reasoning for Video-Grounded Dialogues [link](https://aclanthology.org/2020.emnlp-main.145.pdf)

### Year 2019
* ****`ACL 2019`**** Multimodal Transformer Networks for End-to-End Video-Grounded Dialogue Systems [link](https://aclanthology.org/P19-1564.pdf) [code](https://github.com/henryhungle/MTN)
* ****`ICASSP 2019`**** End-to-end Audio Visual Scene-aware Dialog Using Multimodal Attention-based Video Features [link](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8682583)

## Multimodal Dialog
